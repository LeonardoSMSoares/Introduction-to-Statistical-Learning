{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. In Chapter 4, we used logistic regression to \n",
    "**predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 default student      balance        income\n",
       "0           1      No      No   729.526495  44361.625074\n",
       "1           2      No     Yes   817.180407  12106.134700\n",
       "2           3      No      No  1073.549164  31767.138947\n",
       "3           4      No      No   529.250605  35704.493935\n",
       "4           5      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Default.csv'\n",
    "default = pd.read_csv(file)\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  10000 non-null  int64  \n",
      " 1   default     10000 non-null  object \n",
      " 2   student     10000 non-null  object \n",
      " 3   balance     10000 non-null  float64\n",
      " 4   income      10000 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "default.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  default  student      balance        income\n",
       "0           1        0        0   729.526495  44361.625074\n",
       "1           2        0        1   817.180407  12106.134700\n",
       "2           3        0        0  1073.549164  31767.138947\n",
       "3           4        0        0   529.250605  35704.493935\n",
       "4           5        0        0   785.655883  38463.495879"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_dict = {'Yes': 1, 'No': 0}\n",
    "default['default'] = default['default'].map(encoding_dict)\n",
    "default['student'] = default['student'].map(encoding_dict)\n",
    "\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  10000 non-null  int64  \n",
      " 1   default     10000 non-null  int64  \n",
      " 2   student     10000 non-null  int64  \n",
      " 3   balance     10000 non-null  float64\n",
      " 4   income      10000 non-null  float64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 390.8 KB\n"
     ]
    }
   ],
   "source": [
    "default.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Fit a logistic regression model that uses income and balance to predict default.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[2.77251347 0.26996715]]\n",
      "Intercept: [-6.2137023]\n",
      "Training Accuracy: 0.974875\n",
      "Testing Accuracy: 0.9695\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1921   10]\n",
      " [  51   18]]\n",
      "\n",
      "True Negative: 1921\n",
      "False Positive: 10\n",
      "False Negative: 51\n",
      "True Positive: 18\n",
      "\n",
      "Overall Fraction of Correct Predictions: 0.9695\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in the 'default', 'balance', and 'income' columns\n",
    "default.dropna(subset=['default', 'balance', 'income'], inplace=True)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = default[['balance', 'income']]\n",
    "y = default['default']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print coefficients and intercept\n",
    "print(\"Coefficients:\", log_reg.coef_)\n",
    "print(\"Intercept:\", log_reg.intercept_)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = log_reg.score(X_train_scaled, y_train)\n",
    "test_accuracy = log_reg.score(X_test_scaled, y_test)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Select elements\n",
    "tn = conf_matrix[0][0]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]\n",
    "tp = conf_matrix[1][1]\n",
    "\n",
    "# Overall fraction of correct predictions\n",
    "correct_predictions = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"\\nTrue Negative:\", tn)\n",
    "print(\"False Positive:\", fp)\n",
    "print(\"False Negative:\", fn)\n",
    "print(\"True Positive:\", tp)\n",
    "print(\"\\nOverall Fraction of Correct Predictions:\", correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:**\n",
    "\n",
    "**i. Split the sample set into a training set and a validation set.**\n",
    "\n",
    "**ii. Fit a multiple logistic regression model using only the training observations.**\n",
    "\n",
    "**iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of\n",
    "default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.**\n",
    "\n",
    "**iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error: 0.026249999999999996\n"
     ]
    }
   ],
   "source": [
    "# Step i: Split the sample set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Step ii: Fit a multiple logistic regression model using only the training observations\n",
    "log_reg_val = LogisticRegression()\n",
    "log_reg_val.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step iii: Obtain predictions for the validation set\n",
    "y_val_pred = log_reg_val.predict(X_val_scaled)\n",
    "\n",
    "# Step iv: Compute the validation set error\n",
    "validation_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Set Error:\", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error 1: 0.01953125\n",
      "Validation Set Error 2: 0.02734375\n",
      "Validation Set Error 3: 0.034146341463414664\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = 3\n",
    "\n",
    "# Define lists to store validation set errors\n",
    "validation_errors = []\n",
    "\n",
    "# Repeat the process three times\n",
    "for i in range(num_iterations):\n",
    "    # Step i: Split the sample set into a training set and a validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Step ii: Fit a multiple logistic regression model using only the training observations\n",
    "    log_reg_val = LogisticRegression()\n",
    "    log_reg_val.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Step iii: Obtain predictions for the validation set\n",
    "    y_val_pred = log_reg_val.predict(X_val_scaled)\n",
    "\n",
    "    # Step iv: Compute the validation set error\n",
    "    validation_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "    validation_errors.append(validation_error)\n",
    "\n",
    "# Print the validation errors\n",
    "for i, error in enumerate(validation_errors):\n",
    "    print(f\"Validation Set Error {i+1}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `random_state` parameter in the `train_test_split` function ensures reproducibility by controlling the randomization applied during the data splitting process. However, even with the same random seed, different splits may occur because of the inherent randomness in the process, especially if the dataset is small.\n",
    "\n",
    "In this case, each iteration of the loop performs a new split of the data into training and validation sets. While the `random_state` is set to 42, the randomization process for splitting the data can still lead to slightly different splits in each iteration. This randomness can result in slightly different validation set errors across the iterations, even with the same random seed.\n",
    "\n",
    "Overall, the `random_state` parameter helps ensure that the same randomization process is applied consistently across different runs of the code, allowing for reproducibility, but it does not guarantee identical splits or results in every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error (with student dummy variable): 0.030000000000000027\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the sample set into a training set and a validation set\n",
    "X = default[['balance', 'income', 'student']]\n",
    "y = default['default']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Fit a logistic regression model using income, balance, and the dummy variable for student on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "log_reg_student = LogisticRegression()\n",
    "log_reg_student.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Obtain predictions for the validation set\n",
    "y_val_pred_student = log_reg_student.predict(X_val_scaled)\n",
    "\n",
    "# Compute the validation set error\n",
    "validation_error_student = 1 - accuracy_score(y_val, y_val_pred_student)\n",
    "print(\"Validation Set Error (with student dummy variable):\", validation_error_student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. We continue to consider the use of a logistic regression model \n",
    "**to predict the probability of default using income and balance on the Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the sm.GLM() function. Do not forget to set a random seed before beginning your analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard errors from bootstrap method: [[1.30104261e-18 2.16840434e-18 1.60936260e-20]]\n",
      "Standard errors from standard formula:\n",
      " income     0.000009\n",
      "balance    0.000268\n",
      "student    0.272745\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file = 'data/Default.csv'\n",
    "default = pd.read_csv(file)\n",
    "\n",
    "# Convert 'student' column to binary dummy variable\n",
    "encoding_dict = {'Yes': 1, 'No': 0}\n",
    "default['student'] = default['student'].map(encoding_dict)\n",
    "\n",
    "# Define features (income, balance, student_dummy) and target variable (default)\n",
    "X = default[['income', 'balance', 'student']]\n",
    "y = default['default']\n",
    "\n",
    "# Convert y to numeric type\n",
    "y = y.replace({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert non-numeric columns to appropriate numeric types if necessary\n",
    "X_train['income'] = pd.to_numeric(X_train['income'])\n",
    "X_train['balance'] = pd.to_numeric(X_train['balance'])\n",
    "\n",
    "# Fit a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Compute standard errors using the standard formula\n",
    "X_train_sm = sm.add_constant(X_train)  # Add constant for intercept\n",
    "log_reg_sm = sm.GLM(y_train, X_train_sm, family=sm.families.Binomial()).fit()\n",
    "coef_sm = log_reg_sm.params[1:]  # Exclude intercept\n",
    "std_err_sm = log_reg_sm.bse[1:]  # Standard errors\n",
    "\n",
    "# Fit a logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Compute standard errors using the bootstrap method\n",
    "n_iterations = 1000\n",
    "coef_bootstrap = []\n",
    "for _ in range(n_iterations):\n",
    "    X_resampled, y_resampled = resample(X_train, y_train, replace=True, random_state=42)\n",
    "    log_reg_resampled = LogisticRegression()\n",
    "    log_reg_resampled.fit(X_resampled, y_resampled)\n",
    "    coef_bootstrap.append(log_reg_resampled.coef_)\n",
    "\n",
    "# Compute standard errors using the standard formula\n",
    "X_train_sm = sm.add_constant(X_train)  # Add constant for intercept\n",
    "log_reg_sm = sm.GLM(y_train, X_train_sm, family=sm.families.Binomial()).fit()\n",
    "coef_sm = log_reg_sm.params[1:]  # Exclude intercept\n",
    "std_err_sm = log_reg_sm.bse[1:]  # Standard errors\n",
    "\n",
    "# Compute standard errors from bootstrap results\n",
    "std_err_bootstrap = np.std(coef_bootstrap, axis=0)\n",
    "\n",
    "# Compare the results\n",
    "print(\"Standard errors from bootstrap method:\", std_err_bootstrap)\n",
    "print(\"Standard errors from standard formula:\\n\", std_err_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Bootstrap Method:* The code then computes the standard errors of the coefficients using the bootstrap method. It resamples the training data with replacement, fits logistic regression models to the resampled data, and collects the coefficients. The standard errors are computed from the distribution of the coefficient estimates obtained through resampling.\n",
    "\n",
    "*Standard Formula:* Standard errors are also computed using the standard formula for logistic regression coefficients. This is achieved using the `sm.GLM` class from the statsmodels library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with\n",
    "income and balance in a multiple logistic regression model that uses both predictors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                default   No. Observations:                 8000\n",
      "Model:                            GLM   Df Residuals:                     7996\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -608.26\n",
      "Date:                Sat, 04 May 2024   Deviance:                       1216.5\n",
      "Time:                        10:16:40   Pearson chi2:                 6.61e+03\n",
      "No. Iterations:                     9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -11.3117      0.577    -19.614      0.000     -12.442     -10.181\n",
      "income       7.21e-06   9.46e-06      0.763      0.446   -1.13e-05    2.57e-05\n",
      "balance        0.0059      0.000     21.933      0.000       0.005       0.006\n",
      "student       -0.4881      0.273     -1.790      0.074      -1.023       0.046\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print(log_reg_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Error:\n",
    "\n",
    "    income 9.46e-06\n",
    "    balance ~ 0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Write a function, boot_fn(), that takes as input the Default data set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient estimates for income and balance: [[-0.00012904  0.00049604]]\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Select subset of data based on index\n",
    "    subset_data = data.iloc[index]\n",
    "    \n",
    "    # Define features (income, balance) and target variable (default)\n",
    "    X = subset_data[['income', 'balance']]\n",
    "    y = subset_data['default']\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "\n",
    "    # Return coefficient estimates\n",
    "    return log_reg.coef_\n",
    "\n",
    "# Define an example index\n",
    "index = np.random.choice(default.index, size=len(default), replace=True)\n",
    "\n",
    "# Coefficient estimates\n",
    "coefficients = boot_fn(default, index)\n",
    "print(\"Coefficient estimates for income and balance:\", coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Following the bootstrap example in the lab, use your boot_fn() function to estimate the standard errors of the logistic regression coefficients for income and balance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error for income coefficient: 7.292084410896754e-05\n",
      "Standard error for balance coefficient: 0.002571549382287639\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Select subset of data based on index\n",
    "    subset_data = data.iloc[index]\n",
    "    \n",
    "    # Define features (income, balance) and target variable (default)\n",
    "    X = subset_data[['income', 'balance']]\n",
    "    y = subset_data['default']\n",
    "\n",
    "    # Fit a logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "\n",
    "    # Return coefficient estimates\n",
    "    return log_reg.coef_.flatten()  # Flatten coefficients to ensure consistent format\n",
    "\n",
    "# Initialize lists to store coefficient estimates\n",
    "coef_income = []\n",
    "coef_balance = []\n",
    "\n",
    "# Iterate through bootstrap samples\n",
    "for _ in range(n_iterations):\n",
    "    # Generate bootstrap sample index\n",
    "    index = np.random.choice(default.index, size=len(default), replace=True)\n",
    "    \n",
    "    # Call boot_fn to get coefficient estimates\n",
    "    coefficients = boot_fn(default, index)\n",
    "    \n",
    "    # Append coefficient estimates to lists\n",
    "    coef_income.append(coefficients[0])\n",
    "    coef_balance.append(coefficients[1] if len(coefficients) > 1 else np.nan)  # Handle cases where only one \n",
    "                                                                                # coefficient is returned\n",
    "\n",
    "# Calculate standard errors\n",
    "std_err_income = np.std(coef_income)\n",
    "std_err_balance = np.nanstd(coef_balance)  # Use nanstd to handle NaN values\n",
    "\n",
    "# Print standard errors\n",
    "print(\"Standard error for income coefficient:\", std_err_income)\n",
    "print(\"Standard error for balance coefficient:\", std_err_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Comment on the estimated standard errors obtained using the sm.GLM() function and using the bootstrap.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sm.GLM() function\n",
    "\n",
    "    Standard error for income coefficient: 9.46e-06\n",
    "    Standard error for balance coefficient: ~ 0.000\n",
    "\n",
    "Using the Bootstrap\n",
    "\n",
    "    Standard error for income coefficient: 7.34e-05\n",
    "    Standard error for balance coefficient: 0.0026\n",
    "    \n",
    "while the bootstrap method provides a non-parametric approach to estimate standard errors, it may result in higher variability compared to parametric methods like sm.GLM(). It's essential to consider the assumptions and limitations of both approaches when interpreting the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. In Sections 5.1.2 and 5.1.3, we saw that the cross_validate() function\n",
    "**can be used in order to compute the LOOCV test error estimate. Alternatively, one could compute those quantities using just `sm.GLM()` and the `predict()` method of the fitted model within a for loop. You will now take this approach in order to compute the LOOCV error for a simple logistic regression model on the Weekly data set. Recall that in the context of classification problems, the LOOCV error is given in (5.4).**\n",
    "\n",
    "**(a) Fit a logistic regression model that predicts Direction using Lag1 and Lag2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0  1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1  1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2  1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3  1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4  1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Weekly.csv'\n",
    "weekly = pd.read_csv(file)\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1089 entries, 0 to 1088\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Year       1089 non-null   int64  \n",
      " 1   Lag1       1089 non-null   float64\n",
      " 2   Lag2       1089 non-null   float64\n",
      " 3   Lag3       1089 non-null   float64\n",
      " 4   Lag4       1089 non-null   float64\n",
      " 5   Lag5       1089 non-null   float64\n",
      " 6   Volume     1089 non-null   float64\n",
      " 7   Today      1089 non-null   float64\n",
      " 8   Direction  1089 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "weekly.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly['Direction'] = weekly['Direction'].map({'Down':0,'Up':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.540900\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Up   No. Observations:                 1089\n",
      "Model:                          Logit   Df Residuals:                     1086\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 04 May 2024   Pseudo R-squ.:                     inf\n",
      "Time:                        13:15:36   Log-Likelihood:                -1678.0\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2212      0.061      3.599      0.000       0.101       0.342\n",
      "Lag1          -0.0387      0.026     -1.477      0.140      -0.090       0.013\n",
      "Lag2           0.0602      0.027      2.270      0.023       0.008       0.112\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare the predictors (X) and response (y) variables\n",
    "X = weekly[['Lag1', 'Lag2']]\n",
    "y = pd.get_dummies(weekly['Direction'], drop_first=True)\n",
    "\n",
    "# Add constant to the predictors\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print summary of the logistic regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Fit a logistic regression model that predicts Direction using Lag1 and Lag2 using all but the first observation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.535727\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Up   No. Observations:                 1088\n",
      "Model:                          Logit   Df Residuals:                     1085\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Sat, 04 May 2024   Pseudo R-squ.:                     inf\n",
      "Time:                        13:19:27   Log-Likelihood:                -1670.9\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2232      0.061      3.630      0.000       0.103       0.344\n",
      "Lag1          -0.0384      0.026     -1.466      0.143      -0.090       0.013\n",
      "Lag2           0.0608      0.027      2.291      0.022       0.009       0.113\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Prepare the predictors (X) and response (y) variables\n",
    "X = weekly[['Lag1', 'Lag2']].drop(0,axis = 0)\n",
    "y = pd.get_dummies(weekly['Direction'], drop_first=True).drop(0,axis = 0)\n",
    "\n",
    "# Add constant to the predictors\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Print summary of the logistic regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Model\tLog-Likelihood\tPseudo R-squared\tCoefficient Significance (p-values)\n",
    "    A\t      -1678.0\t         inf\t          Lag1: 0.140, Lag2: 0.023\n",
    "    B\t      -1670.9\t         inf\t          Lag1: 0.143, Lag2: 0.022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models have `pseudo R-squared` values of `inf`, indicating perfect separation of the data. However, this is likely due to a small number of distinct values in the dependent variable.\n",
    "\n",
    "The coefficients for `Lag1` and `Lag2` are not statistically significant at the 0.05 significance level for both models, as their `p-values` are greater than 0.05. However, the constant term (const) is statistically significant in both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Use the model from (b) to predict the direction of the first observation. You can do this by predicting that the first observation will go up if P(Direction = \"Up\"|Lag1, Lag2) > 0.5. Was this observation correctly classified?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted - 1\n",
      "True value - 0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "file = 'data/Weekly.csv'\n",
    "weekly = pd.read_csv(file)\n",
    "\n",
    "# Convert 'Direction' column to binary dummy variable\n",
    "encoding_dict = {'Up': 1, 'Down': 0}\n",
    "weekly['Direction'] = weekly['Direction'].map(encoding_dict)\n",
    "\n",
    "# Prepare the predictors (X) and response (y) variables\n",
    "X_train = weekly[['Lag1', 'Lag2']].iloc[1:]\n",
    "y_train = pd.get_dummies(weekly['Direction'], drop_first=True).iloc[1:]\n",
    "\n",
    "# Build regression model\n",
    "clf = LogisticRegression().fit(X_train,y_train)\n",
    "\n",
    "# Prepare the predictors (X_test) for the single observation\n",
    "X_test = weekly[['Lag1', 'Lag2']].iloc[[0]]\n",
    "\n",
    "# Save predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Real value\n",
    "y_test = weekly['Direction'].loc[0]   \n",
    "\n",
    "print('Predicted - {}\\nTrue value - {}'.format(int(clf.predict(X_test)),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Write a for loop from i = 1 to i = n, where n is the number of observations in the data set, that performs each of the following steps:**\n",
    "\n",
    "**i. Fit a logistic regression model using all but the ith observation to predict Direction using Lag1 and Lag2.**\n",
    "\n",
    "**ii. Compute the posterior probability of the market moving up for the ith observation.**\n",
    "\n",
    "**iii. Use the posterior probability for the ith observation in order to predict whether or not the market moves up.**\n",
    "\n",
    "**iv. Determine whether or not an error was made in predicting the direction for the ith observation. If an error was made, then indicate this as a 1, and otherwise indicate it as a 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the errors\n",
    "errors = []\n",
    "\n",
    "# Iterate over each observation in the dataset\n",
    "for i in range(len(weekly)):\n",
    "    # Prepare predictors and response variables, excluding the ith observation\n",
    "    X_train = weekly[['Lag1', 'Lag2']].drop(i, axis=0)\n",
    "    y_train = pd.get_dummies(weekly['Direction'], drop_first=True).drop(i, axis=0)\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Prepare the predictors for the ith observation\n",
    "    X_test = weekly[['Lag1', 'Lag2']].iloc[[i]]\n",
    "\n",
    "    # Compute the posterior probability of the market moving up for the ith observation\n",
    "    posterior_prob = clf.predict_proba(X_test)[0, 1]\n",
    "\n",
    "    # Use the posterior probability to predict whether the market moves up\n",
    "    prediction = 1 if posterior_prob > 0.5 else 0\n",
    "\n",
    "    # Determine if an error was made in predicting the direction for the ith observation\n",
    "    true_direction = weekly['Direction'].iloc[i]\n",
    "    error = 1 if prediction != true_direction else 0\n",
    "\n",
    "    # Append the error to the list\n",
    "    errors.append(error)\n",
    "\n",
    "# Print the list of errors\n",
    "print(\"Errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: [1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Sum of '1's: 490\n",
      "Sum of '0's: 599\n",
      "Ratio of errors: 0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store the errors\n",
    "errors = []\n",
    "\n",
    "# Initialize variables to store the sum of '1's and '0's\n",
    "sum_ones = 0\n",
    "sum_zeros = 0\n",
    "\n",
    "# Iterate over each observation in the dataset\n",
    "for i in range(len(weekly)):\n",
    "    # Prepare predictors and response variables, excluding the ith observation\n",
    "    X_train = weekly[['Lag1', 'Lag2']].drop(i, axis=0)\n",
    "    y_train = pd.get_dummies(weekly['Direction'], drop_first=True).drop(i, axis=0)\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    # Prepare the predictors for the ith observation\n",
    "    X_test = weekly[['Lag1', 'Lag2']].iloc[[i]]\n",
    "\n",
    "    # Compute the posterior probability of the market moving up for the ith observation\n",
    "    posterior_prob = clf.predict_proba(X_test)[0, 1]\n",
    "\n",
    "    # Use the posterior probability to predict whether the market moves up\n",
    "    prediction = 1 if posterior_prob > 0.5 else 0\n",
    "\n",
    "    # Determine if an error was made in predicting the direction for the ith observation\n",
    "    true_direction = weekly['Direction'].iloc[i]\n",
    "    error = 1 if prediction != true_direction else 0\n",
    "\n",
    "    # Append the error to the list\n",
    "    errors.append(error)\n",
    "\n",
    "    # Update the sum of '1's and '0's\n",
    "    if error == 1:\n",
    "        sum_ones += 1\n",
    "    else:\n",
    "        sum_zeros += 1\n",
    "\n",
    "# Calculate the ratio of errors\n",
    "ratio = sum_ones / len(weekly)\n",
    "\n",
    "# Print the list of errors\n",
    "print(\"Errors:\", errors)\n",
    "print(\"\\nSum of '1's:\", sum_ones)\n",
    "print(\"Sum of '0's:\", sum_zeros)\n",
    "print(\"Ratio of errors:\", ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Take the average of the n numbers obtained in (d)iv in order to obtain the LOOCV estimate for the test error. Comment on the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV estimate for test error: 0.44995408631772266\n"
     ]
    }
   ],
   "source": [
    "# Calculate the LOOCV estimate for the test error\n",
    "loocv_error = sum(errors) / len(errors)\n",
    "\n",
    "# Print the LOOCV estimate for the test error\n",
    "print(\"LOOCV estimate for test error:\", loocv_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. We will now perform cross-validation on a simulated data set.\n",
    "**(a) Generate a simulated data set as follows:**\n",
    "\n",
    "    rng = np.random.default_rng(1)\n",
    "    x = rng.normal(size=100)\n",
    "    y = x - 2 * x**2 + rng.normal(size=100)\n",
    "    \n",
    "**In this data set, what is n and what is p? Write out the model used to generate the data in equation form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
